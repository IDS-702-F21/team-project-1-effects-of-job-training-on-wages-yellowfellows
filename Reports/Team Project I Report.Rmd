---
title: "IDS702 Team Project I Yellow"
author: "Athena Liu, Anna Dai, Moritz Wilksch, Dauren Bizhanov, Himangshu Ray Bhantana"
date: "9/25/2021"
output:
  pdf_document: default
---

```{r, echo = FALSE, include=FALSE}
#import data files and clean data
rm(list = ls())

library(ggplot2)
library(MASS)
library(rms)

data <- read.csv("../Data/lalondedata.txt", sep=',')

data$treat <- as.factor(data$treat)
data$black <- as.factor(data$black)
data$hispan <- as.factor(data$hispan)
data$married <- as.factor(data$married)
data$nodegree <- as.factor(data$nodegree)
data$diff_re <- data$re78 - data$re75
```

# Summary
Part 1
Part 2

# Introduction

Many public policy programs in the United States aimed to help improve personal income. In order to evaluate the effectiveness of these public policy programs, a group of researchers conducted several randomized experiments with the programs in the 1970s. We closely examined the experiment National Supported  Work (NSW) Demonstration in this analysis. Participants of this experiment were randomly assigned to recieve job training. Using data from this experiment, researchers attempted to assess the effectiveness of job training for disadvantaged workers in increasing their wages. This analysis focused on investigating two topics of interest. First, is there evidence that workers who receive job training tend to earn higher wages than workers who do not receive job training? Second, is there evidence that workers who receive job training tend to be more likely to have positive (non-zero) wages than workers who do not receive job training? To answer these questions, we used statistical models such as linear regression and logistic regression to infer the relationship between the response variable, wage difference between 1974 and 1978, and the predictor variables such as treatment, educational background, racial identity, etc.

# Data
In this analysis, we used the dataset from National Supported Work Demonstration and included only male participants. This dataset contains several variables that are useful in assessing whether the job training for disadvantage workers is helpful in improving income.The response variable in this analysis is re78 minus re74, annual earnings difference between 1974 and 1978. Potential predictor variables in this analysis includes treatment (received training or non), years of education, marital status, and racial identity (Black or Hispanic), and annual earnings in 1975. The treatment group in this analysis includes individuals who received training. Control group includes participants who didn't received training and was below the poverty line in 1975. We conducted exploratory data analysis between the response and predictor variables prior to constructing the statistical models, and this section demonstrates a few variables that could be significant to our statistical models. 

We started exploring the dataset by observing the univairate relationship between reponse and predictor variables.

```{r, echo = FALSE}
ggplot(data, aes(x=black, y=re78)) + geom_boxplot() + ggtitle("Black vs. re78") + theme(plot.title = element_text(hjust = 0.5))

ggplot(data, aes(x=married, y=re78)) + geom_boxplot() + ggtitle("Married vs. re78") + theme(plot.title = element_text(hjust = 0.5))
```
```{r, echo = FALSE}
ggplot(data, aes(x=treat, y=re78)) + geom_boxplot() + facet_wrap(~black, ncol=4) + ggtitle("Treament vs. re78 By Black") + theme(plot.title = element_text(hjust = 0.5))
```

# Model

## Part I
model experimented with (baseline model base on EDA)
baseline_model <- lm(re78 ~ treat + married + black + black*treat, data=data) (reference)
started without re74, used predictors we found interesting based on the EDA. model really bad

Used AIC model selection algorithm
null model, just treatment
full model, all variables but not interactions
Forward, backward, and step wise - backward gave constant model, so examine forward and step wise model only. They gave the same model. Also not looking hot. R squared is not good, actual shape of residual plot not good, assumptions not satisfied

Performed another AIC step wise. same null model, full model now includes any interactions with treatment and predictors that we found significant previously. No interactions were kept. 

At this point, we looked at transformation. And, to eliminate the effects of 0 in the data, we added one to all the points in re78. Then we log transformation re78. But, the results were even more horrifying. 

Final model.
re74, that what improved the model.

How did we spotted the outliers? Cook distance, spot high leverage outlier, not high influence
Outliers removed. Waiting for new plot on Monday. Index specific outlier, what they are, why is it okay to remove them?

Our final model is looking goooooood now. Talk about assumptions again. Why is it better? It use to be 0.03 which is complete trash. Lol even 0.14 is not good, we feel done with this model. 

model interpretation: 
Every dollar increased in pre-treatment earnings in 1974 


-----------------TODO center data, remove outliers--------------------

Call:
lm(formula = re78 ~ treat + re74 + educ + black, data = data_wo)

Residuals:
   Min     1Q Median     3Q    Max 
-13513  -4808  -1609   3864  28231 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.716e+03  1.110e+03   1.547 0.122463    
treat1       1.236e+03  7.272e+02   1.700 0.089720 .  
re74         3.605e-01  4.392e-02   8.209 1.34e-15 ***
educ         3.435e+02  1.025e+02   3.350 0.000857 ***
black1      -1.549e+03  6.820e+02  -2.272 0.023460 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 6531 on 606 degrees of freedom
Multiple R-squared:  0.1463,	Adjusted R-squared:  0.1407 
F-statistic: 25.97 on 4 and 606 DF,  p-value: < 2.2e-16


## Part II

# Conclusion

